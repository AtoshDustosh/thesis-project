// -------------------------- 对unmapped reads的处理 ----------------------------

步骤简述:
	1. 把reference sequence按照给定的数组分割成许多段split1[]，每段的起始位置都在数组中给出

	2. 把第一次分割后得到的split1[]继续分割，假设选取split1[]中的一段，将其分割为split2[]，按照另一个给定的长度，比如每段200bp，最后一段如果不足200bp，则只保留不足200bp的部分，不做填充

	3. 分割后得到的split2[]中，选取某一段part，提取part范围内所有的变异var[]并做组合处理，得到combinatins[]，然后对每一种变异的组合做整合处理，得到新的序列part_integrated

	有当时的讨论记录但是现在考虑时感觉不确定的几点：
		3.1 整合后根据情况可能导致part的长度发生改变，极端情况下可能part完全被删除，或者part长度变得非常长
		3.2 不论整合后part如何，把它所有的kmer提取出来
		3.3 最终目的是得到每个提取的kmer的数据组 (const char *kmer, int64_t pos)（kmer或许需要经过编码）


程序部分的问题：
	if(程序直接在index_build.c里的函数load_reffile_kmer_fa()的第一个while循环里面写){
		1. 如何测试？
			如题 ... 
		2. 其它问题待定，正在看代码 - 大概率看不明白
	}else{	// 如果可以在其他程序中处理，然后把结果写入某个外部文件的话
		方案：可以用最近写的代码来做这件事，把所有整合变异后的kmer提取出来，之后按照某个格式写入输出文件。
		虽然没有hash table来存kmer，但是如果只是为了得到二元组的话没有问题（而且这样实现起来很快，因为基本所有的结构和函数都有了）
		然而根据index_build.c里130多行的注释，好像是需要把kmer存入 “write_buff” 这个数组内，所以这个方案不符合要求。
		但是因为这个方案实现起来特别快速，所以暂时保留。
		不过，因为读取参考基因组时格式可能有格式问题，或者其他的各种参数设置上的问题，这个方案也需要一些改动才能实现。
	}